Introducción a la Clase de Álgebra Lineal
Buenos días y bienvenidos a la primera sesión de nuestra clase de Álgebra Lineal. Me complace ver caras nuevas dispuestas a embarcarse en este viaje por uno de los campos más fundamentales de las matemáticas. Durante este curso, desentrañaremos los misterios de los vectores, las matrices, los determinantes, los espacios vectoriales y más, explorando cómo estos conceptos se entrelazan para formar la estructura sobre la que descansa gran parte del pensamiento matemático moderno.
¿Qué es el Álgebra Lineal?, porfavor silencio chicos que comenzaré la clase en estos momentos. afasasf
El álgebra lineal es el estudio de vectores, espacios vectoriales (también conocidos como espacios lineales), y transformaciones lineales. Es un lenguaje poderoso que nos permite describir y resolver complejas operaciones en dimensiones múltiples. No solo es una piedra angular en casi todos los campos de las matemáticas, sino que también tiene aplicaciones prácticas en ciencias como la física, la estadística, la ingeniería, la economía, la informática y más.
Vectores y Operaciones
Comenzaremos con los vectores, que pueden considerarse como flechas en un espacio que tienen dirección y magnitud. Los vectores son fundamentales, no sólo en matemáticas, sino también en la vida real. Desde representar fuerzas en física hasta desplazamientos en robótica, los vectores son omnipresentes.
Hoy aprenderemos cómo sumar y restar vectores, cómo multiplicarlos por escalares y entenderemos conceptos como la longitud o norma de un vector y la idea de vectores unitarios.
Matrices y Sistemas de Ecuaciones Lineales
Después, avanzaremos hacia las matrices. Una matriz no es más que una tabla rectangular de números que puede representar un sistema de ecuaciones lineales. Resolveremos estos sistemas utilizando métodos como la eliminación gaussiana y discutiremos cómo la inversión de matrices puede ser una herramienta poderosa.
profesor no entendí porque mencionó las flechas para comparar vectore?
Pues necesitaremos hacer un dibujo, mira aqui puedes ver que el vector se puede representar mediante una flecha que tiene un largo o manigut y apunta en una direccion y sentido. 
aah ahora entendi, disculpe.
No se preocupen, todas las preguntas que tengan haganlas ahora y no antes de la prueba.
asad
Determinantes
También introduciremos brevemente el concepto de determinantes, que es un número que puede decirnos mucho sobre la matriz en sí. Por ejemplo, si un determinante es cero, nos indica que el sistema asociado de ecuaciones no tiene una solución única.
Conclusión de la Introducción
Este es solo el comienzo de lo que será un emocionante y desafiante viaje intelectual. Al final de este curso, tendrán las herramientas para comprender y realizar operaciones complejas que son cruciales en campos avanzados de estudio y en aplicaciones prácticas en diversas industrias.
Les animo a que se involucren, pregunten siempre y aprovechen al máximo los recursos que se proporcionarán durante las próximas semanas. ¡Empecemos con el fascinante mundo del álgebra lineal!
Matrices: Definición y Propiedades Básicas
Después de nuestra introducción a los conceptos fundamentales de vectores y sus operaciones, ahora nos adentraremos en el estudio de las matrices. Una matriz es, en esencia, un arreglo bidimensional de números organizados en filas y columnas. Esta disposición no es arbitraria; refleja una estructura que podemos manipular de formas muy específicas para resolver problemas matemáticos.
pueden salir por un momento, recuerden que de lo definidoa nteriormente tendrán que realizar una tarea. La siguiente guia tiene ejercicios de suma de vectore,s suma de matrices y operaciones elementales en espacios vectoriale.s 
¿Qué Representa una Matriz?

Las matrices pueden representar muchas cosas: pueden ser sistemas de ecuaciones lineales, transformaciones lineales, o simplemente colecciones de vectores. Cada número en una matriz se denomina un elemento de la matriz.

Tipos de Matrices

Existen varios tipos de matrices, como matrices cuadradas, matrices rectangulares, matrices diagonales, matrices escalonadas, entre otras. Cada tipo tiene propiedades particulares que a menudo pueden simplificar nuestras operaciones y cálculos.

Operaciones con Matrices

En cuanto a las operaciones, podemos sumar o restar matrices del mismo tamaño, es decir, que tienen el mismo número de filas y columnas. También podemos multiplicar matrices, pero para que esto sea posible, el número de columnas en la primera matriz debe coincidir con el número de filas en la segunda matriz. La multiplicación de matrices no es conmutativa, lo que significa que el orden en el que multiplicamos las matrices es crucial.

La Matriz Identidad y la Inversa de una Matriz

Hablaremos también sobre la matriz identidad, que es una matriz cuadrada que en la multiplicación actúa como el número 1 en la aritmética ordinaria. Relacionado con esto está el concepto de matriz inversa, que es una matriz que, cuando se multiplica por la matriz original, da como resultado la matriz identidad.

Determinantes e Invertibilidad

El determinante es una propiedad numérica que solo tienen las matrices cuadradas. Nos permite saber si una matriz es invertible o no; es decir, si tiene una matriz inversa. Una matriz es invertible solo si su determinante es distinto de cero.

Aplicaciones de las Matrices

Las matrices tienen aplicaciones prácticas extensas. Por ejemplo, en informática, se utilizan para representar datos y en gráficos por computadora para realizar operaciones de transformación. En ingeniería y física, las matrices son esenciales para describir sistemas complejos y realizar simulaciones.

Resumen de la Sección

Hoy hemos cubierto solo lo más básico sobre las matrices. Es importante que se familiaricen con estas operaciones y conceptos, ya que serán la base para temas más avanzados que exploraremos en clases futuras, como el rango de una matriz, el teorema de la matriz invertible y las descomposiciones matriciales.

Para la próxima sesión, les pido que lean el capítulo correspondiente a matrices en su libro de texto y que resuelvan los ejercicios propuestos. Esto les ayudará a asentar las bases para lo que viene.

¿Preguntas? No duden en acercarse después de la clase o en horario de tutorías si necesitan aclarar dudas o profundizar en algún tema.

El producto escalar (o producto punto) de dos vectores produce un escalar y es una operación fundamental que nos da una medida de la magnitud de un vector en la dirección del otro. El producto escalar se define como:

a
⃗
⋅
b
⃗
=
a
1
b
1
+
a
2
b
2
a
 ⋅ 
b
 =a 
1
​	
 b 
1
​	
 +a 
2
​	
 b 
2
​	
 
Para tres dimensiones: 
a
⃗
⋅
b
⃗
=
a
1
b
1
+
a
2
b
2
+
a
3
b
3
Para tres dimensiones:  
a
 ⋅ 
b
 =a 
1
​	
 b 
1
​	
 +a 
2
​	
 b 
2
​	
 +a 
3
​	
 b 
3
​	
 

El producto escalar tiene una interpretación geométrica importante: es el producto de las magnitudes de los dos vectores y el coseno del ángulo entre ellos.

Producto Vectorial

En tres dimensiones, también tenemos el producto vectorial (o producto cruz), que da como resultado un vector que es perpendicular a ambos vectores iniciales. El módulo de este vector es proporcional al área del paralelogramo que forman los dos vectores originales.

a
⃗
×
b
⃗
=
(
a
2
b
3
−
a
3
b
2
,
a
3
b
1
−
a
1
b
3
,
a
1
b
2
−
a
2
b
1
)
a
 × 
b
 =(a 
2
​	
 b 
3
​	
 −a 
3
​	
 b 
2
​	
 ,a 
3
​	
 b 
1
​	
 −a 
1
​	
 b 
3
​	
 ,a 
1
​	
 b 
2
​	
 −a 
2
​	
 b 
1
​	
 )

El producto vectorial es muy útil en física, por ejemplo, para calcular el torque o el momento angular.

Combinación Lineal

Una combinación lineal de vectores implica la construcción de un nuevo vector al sumar múltiplos escalares de otros vectores. Dados varios vectores 
v
⃗
1
,
v
⃗
2
,
.
.
.
,
v
⃗
n
v
  
1
​	
 , 
v
  
2
​	
 ,..., 
v
  
n
​	
  y escalares 
c
1
,
c
2
,
.
.
.
,
c
n
c 
1
​	
 ,c 
2
​	
 ,...,c 
n
​	
 , la combinación lineal es:

c
1
v
⃗
1
+
c
2
v
⃗
2
+
.
.
.
+
c
n
v
⃗
n
c 
1
​	
  
v
  
1
​	
 +c 
2
​	
  
v
  
2
​	
 +...+c 
n
​	
  
v
  
n
​	
 

Las combinaciones lineales son extremadamente importantes porque nos permiten explorar conceptos como la dependencia e independencia lineal, que a su vez llevan a la idea de la base de un espacio vectorial.

Norma de un Vector

La norma o magnitud de un vector 
a
⃗
a
  se denota como 
∣
∣
a
⃗
∣
∣
∣∣ 
a
 ∣∣ y se calcula mediante la raíz cuadrada de la suma de los cuadrados de sus componentes. En dos dimensiones:

∣
∣
a
⃗
∣
∣
=
a
1
2
+
a
2
2
∣∣ 
a
 ∣∣= 
a 
1
2
​	
 +a 
2
2
​	
 
​	
 
En tres dimensiones: 
∣
∣
a
⃗
∣
∣
=
a
1
2
+
a
2
2
+
a
3
2
En tres dimensiones: ∣∣ 
a
 ∣∣= 
a 
1
2
​	
 +a 
2
2
​	
 +a 
3
2
​	
 
​	
 

La norma nos da una medida de la "longitud" del vector en el espacio.
Para sumar o restar matrices, simplemente sumamos o restamos los elementos correspondientes de cada matriz. Esto solo tiene sentido si las matrices tienen las mismas dimensiones. Es decir, si tenemos dos matrices A y B de dimensiones 
m
×
n
m×n, adentraremosLa suma de A y B, denotada como a mas B, la resta se hace de forma analoga
Multiplicar matrices es más complejo que sumarlas o restarlas. No podemos simplemente multiplicar los elementos correspondientes. En su lugar, cada elemento de la matriz producto se obtiene sumando los productos de los elementos correspondientes de la fila de la primera matriz y la columna de la segunda matriz.
Si tenemos dos matrices \( A \) de dimensiones \( m \times n \) y \( B \) de dimensiones \( n \times p \), su producto \( AB \) será una matriz de dimensiones \( m \times p \) donde el elemento en la i-ésima fila y j-ésima columna se calcula como:
\[ (AB)_{ij} = \sum_{k=1}^n a_{ik} b_{kj} \]
**Propiedades de la Multiplicación Matricial**
- No conmutativa: \( AB \neq BA \)
- Asociativa: \( A(BC) = (AB)C \)
- Distributiva: \( A(B+C) = AB + AC \)
- Elemento neutro: \( AI = IA = A \), donde \( I \) es la matriz identidad
**Matriz Transpuesta**
La transpuesta de una matriz \( A \), denotada como \( A^T \), es una nueva matriz donde las filas de \( A \) son las columnas de \( A^T \) y viceversa.
**Matriz Inversa**
La matriz inversa de una matriz cuadrada \( A \), denotada como \( A^{-1} \), es aquella que, cuando se multiplica por \( A \), resulta en la matriz identidad:
\[ AA^{-1} = A^{-1}A = I \]
Solo las matrices cuadradas con determinante no nulo tienen inversa.
**Determinante**
El determinante de una matriz cuadrada \( A \), denotado \( \det(A) \) o \( |A| \), es un valor que puede decirnos mucho sobre la matriz. Es una función que asigna a cada matriz cuadrada un número real. Tiene propiedades importantes, como por ejemplo:
- \( \det(AB) = \det(A) \cdot \det(B) \)
- \( A \) es invertible si y solo si \( \det(A) \neq 0 \)
**Rango de una Matriz**
El rango de una matriz \( A \), denotado como \( \text{rank}(A) \), es la dimensión del espacio vectorial generado por sus columnas (o filas). Esencialmente, nos dice cuántas filas o columnas son linealmente independientes.
Estas operaciones matriciales son las herramientas básicas que usaremos al trabajar con matrices en álgebra lineal, y son esenciales para entender los sistemas de ecuaciones lineales, transformaciones lineales, espacios vectoriales, y más. La práctica en la ejecución de estas operaciones es crucial para desarrollar la intuición y la habilidad para aplicar el álgebra lineal a problemas prácticos.
Sea V un K-espacio vectorial. Un subconjunto S ⊆ V no vac ́ıo se dice un subespacio de V si la suma y el producto por escalares (de V ) son una operaci ́on y una acci ́on en S que lo convierten en un K-espacio vectorial.
Ejemplo. Caractericemos todos los subespacios de R2:
• S = {(0, 0)} es un subespacio.
• Supongamos que S es un subespacio y que contiene algu ́n elemento v no nulo. Entonces, para todo λ ∈ R, λ.v ∈ S. Si  ́estos son todos los elementos de S, entonces S es un subespacio (que, gr ́aficamente, resulta ser una recta que pasa por el origen).
• Con la notaci ́on del punto anterior, si S contiene algu ́n elemento que no es de la forma λ.v, digamos v′, contiene tambi ́en a todos los mu ́ltiplos de v′. Luego, S contiene a las dos rectas L y L′ que pasan por el origen y cuyas direcciones son v y v′ respectivamente. Es claro (usando la regla del paralelogramo) que cualquier punto en R2 es suma de un elemento de L m ́as uno de L′, luego pertenece a S. En consecuencia, S = R2.
Observamos que, dado un K-espacio vectorial V y un subconjunto S de V , para determinar si S es un subespacio de V segu ́n la Definici ́on 1.9 debemos verificar la validez de una gran cantidad de propiedades (todas las involucradas en la definici ́on de espacio vectorial). La siguiente proposici ́on nos provee una caracterizaci ́on de los subespacios en t ́erminos de s ́olo tres propiedades, a partir de las cuales se deducen todas las dem ́as.
Proposici ́on 1.10 Sea V un K-espacio vectorial y sea S ⊆ V . Entonces S es un subes- pacio de V si y s ́olo si valen las siguientes condiciones:
i) 0 ∈ S
ii) v,w∈S=⇒v+w∈S
iii) λ∈K,v∈S=⇒λ·v∈S Demostracio ́n.
(⇒) Es inmediato verificar que si S es un subespacio de V se cumplen i), ii) e iii).
(⇐) La condici ́on i) asegura que S es no vac ́ıo.
Por ii), + es una operaci ́on de S y por iii), · es una acci ́on.
La asociatividad y conmutatividad de la suma se deducen de la validez de las mismas para V , el elemento neutro de la suma 0 ∈ S por i), y la existencia de inverso aditivo se deduce de que dado v ∈ S, −v = (−1) · v, que pertenece a S por iii).
Las propiedades de la acci ́on en la definici ́on de espacio vectorial se deducen tambi ́en de su validez en V. ¤
Observamos que la condici ́on i) en la proposici ́on anterior puede ser reemplazada por
 
1.1 Espacios vectoriales y subespacios 9
i′) S ̸= ∅.
Es decir, las condiciones i), ii), iii) son equivalentes a i’), ii), iii). La demostraci ́on de este
hecho queda como ejercicio.
Ejemplos. Sea V un K-espacio vectorial.
1. {0} es un subespacio de V .
2. V es un subespacio de V .
3. Siv∈V,S={λ·v/λ∈K}esunsubespaciodeV:
i) 0=0·v∈S.
ii) Siλ·v,μ·v∈S,entoncesλ·v+μ·v=(λ+μ)·v∈S.
iii) Siλ·v∈Syα∈K,entoncesα·(λ·v)=(α·λ)·v∈S.
Este subespacio se denomina el subespacio generado por v y se nota S = < v >.
4. Seanv1,...,vn ∈V.
EntoncesS={α1.v1+···+αn.vn :αi ∈K, 1≤i≤n}esunsubespaciodeV:
i) 0=0.v1 +···+0.vn ∈S.
ii) Siv,w∈S,v=α1.v1+···+αn.vn,w=β1.v1+···+βn.vn,entonces
v+w=(α1 +β1).v1 +···+(αn +βn).vn ∈S. iii) Si λ ∈ K y v = α1.v1 + · · · + αn.vn ∈ S, entonces
λ.v = (λ.α1).v1 + · · · + (λ.αn).vn ∈ S.
El subespacio S que hemos definido se llama el subespacio generado por v1, . . . , vn y se
nota S = < v1,...,vn >.
Si V es un K-espacio vectorial, tiene sentido considerar las operaciones de uni ́on e inter- secci ́on entre subespacios de V (que son subconjuntos de V ). Una pregunta que surge es si estas operaciones preservan la estructura de subespacio. Como veremos a continuaci ́on, esto vale en el caso de la intersecci ́on de subespacios, pero no para la uni ́on.
Proposici ́on 1.11 Sea V un K-espacio vectorial, y sean S y T subespacios de V . Entonces S∩T es un subespacio de V.
Demostraci ́on.
i) 0 ∈ S ∩ T puesto que 0 ∈ S y 0 ∈ T .
ii) Seanv,w∈S∩T. Entoncesv∈S,v∈T,w∈Syw∈T. Comov,w∈SySesun subespacio,entoncesv+w∈S. An ́alogamente,v+w∈T. Luego,v+w∈S∩T.
 
10 Espacios vectoriales
iii)Seanλ∈Kyv∈S∩T. Entoncesv∈Syv∈T. Comoλ∈K,v∈SySesun subespacio,entoncesλ·v∈S. An ́alogamente,λ·v∈T. Luego,λ·v∈S∩T. ¤
En forma an ́aloga a lo hecho en la demostraci ́on de la proposici ́on anterior, se prueba que la intersecci ́on de cualquier familia de subespacios de un K-espacio vectorial V es un subespacio de V .
Observaci ́on 1.12 Si V es un K-espacio vectorial, S y T subespacios de V , entonces S ∪ T no es necesariamente un subespacio de V .
En efecto, consideremos en R2 los subespacios S = < (1, 0) > y T = < (0, 1) >. Observamos que (1,0) ∈ S y (0,1) ∈ T; luego, ambos pertenecen a S ∪ T. Pero (1,0) +
(0, 1) = (1, 1) ∈/ S ∪ T , puesto que (1, 1) ∈/ S y (1, 1) ∈/ T .
Concluimos esta secci ́on exhibiendo algunos ejemplos de subespacios de distintos K-
espacios vectoriales.
Ejemplos.
1. Sean a1,...,an ∈ K fijos. Sea S = {(x1,...,xn) ∈ Kn : a1x1 + ···anxn = 0}. Es f ́acil verificar que S es un subespacio de Kn.
 ( a11x1+···+a1nxn=0 )
(x1,...,xn) ∈ Kn : . es un subespacio de Kn, pues
S= Tm Si,dondeSi ={(x1,...,xn)∈Kn :ai1x1+···+ainxn =0}(1≤i≤m)y i=1 n
cada Si es un subespacio de K .
3. Sean V = K[X] y n ∈ N fijo. Se tiene que Kn[X] = {f ∈ K[X] / f = 0 o gr(f) ≤ n}
es un subespacio de V : i) 0 ∈ Kn[X].
ii) Seanf,g∈Kn[X]. Sif =0og=0esclaroquef+g∈S. Sif+g=0,entonces f+g∈S. Sino,gr(f+g)≤max(gr(f),gr(g))≤n,yporlotantof+g∈S.
iii) Sean λ ∈ K y f ∈ Kn[X]. Si λ = 0 o f = 0, entonces λ.f = 0 ∈ Kn[X]. Si no, gr(λ.f) = gr(f), de donde λ.f ∈ Kn[X].
Observar que el conjunto {f ∈ K[X] / f = 0 o gr(f) ≥ n}, para n ∈ N fijo, no es un subespacio de K[X]. Por ejemplo: f = Xn y g = −Xn +1 pertenecen a dicho conjunto, pero f + g = 1 no.
1.1.4 Sistemas de generadores
El objetivo de esta secci ́on es mostrar c ́omo pueden describirse todos los elementos de un K-espacio vectorial V a partir de ciertos subconjuntos de elementos de V .
2. S =
am1x1 +···+amnxn =0

1.1 Espacios vectoriales y subespacios 11
De la definici ́on de K-espacio vectorial vemos que una forma de obtener nuevos elementos de V a partir de los elementos de un subconjunto G ⊆ V es considerando sumas finitas de mu ́ltiplos por escalares de elementos de G. Surge entonces la noci ́on de combinaci ́on lineal:
Definici ́on 1.13 Sea V un K-espacio vectorial, y sea G = {v1,...,vr} ⊆ V. Una com- binaci ́on lineal de G es un elemento v ∈ V tal que v = Pr αi.vi con αi ∈ K para cada
 1 ≤ i ≤ r. Ejemplos.
i=1
1. Sea G = {(1, 2), (3, 4)} ⊆ R2. Una combinaci ́on lineal de G es un vector v = α.(1, 2) + β.(3,4) con α,β ∈ R.
2. Sea G = {1,X,...,Xn} ⊆ Rn[X]. Una combinaci ́on lineal de G es Pn αiXi con αi ∈ R
i=0
para cada 0 ≤ i ≤ n.
La definici ́on de combinaci ́on lineal se extiende al caso de subconjuntos no necesariamente
finitos del espacio vectorial considerado:
Definici ́on 1.14 Sea V un K-espacio vectorial, sea I un conjunto de  ́ındices y sea G =
{vi/i∈I}⊂V. Unacombinacio ́nlinealdeGesunelementov∈V talquev=Pαi.vi
donde αi = 0 salvo para finitos i ∈ I. Ejemplos.
i∈I
1. SeaG={Xi/i∈N0}⊆R[X]. Unacombinacio ́nlinealdeGes P∞ αiXi dondeαi ∈R
α∈R
Dado un espacio vectorial V , considerando las combinaciones lineales de los elementos de ciertos subconjuntos de V , podemos obtener cualquier elemento del espacio vectorial en cuestio ́n. Como se ver ́a en los ejemplos, en muchos casos esto nos permitir ́a describir conjuntos infinitos (como por ejemplo R2) utilizando finitos elementos del espacio.
Definici ́on 1.15 Sea V un K-espacio vectorial y sea G ⊆ V . Se dice que G es un sistema de generadores de V (y se nota < G > = V ) si todo elemento de V es una combinaci ́on lineal de G.
i=0
2. Sea G = {(α,0) : α ∈ R} ⊆ R2. Una combinaci ́on lineal de G es P βα.(α,0) tal que
y αi = 0 salvo para finitos valores de i ∈ N0. βα ∈Ryβα =0salvoparafinitosα∈R.

12 Espacios vectoriales
Ejemplos.
1. R2 =<(1,0),(0,1)>,pues∀x=(α,β)∈R2,x=α.(1,0)+β.(0,1).
2. Kn = < (1,0...,0),(0,1,0,...,0),...,(0,...,0,1,0,...,0),...,(0,...,0,1) >.
ij
< G >:
Es claro que 0 ∈ <G>. Veamos, por inducci ́on en gr(g), que g ∈ <G> para cada
g ∈ K[X].
 n×m
4. K[X] =< Xi >i∈N0 .
ij
n1 sik=iyj=l 0 sino
3. K
5. SiG⊆K[X]talqueparacadai∈N0,existefi ∈Gcongr(fi)=i,entoncesK[X]=
= < E
> 1≤i≤n 1≤j≤m
donde (E
)kl =
Sigr(g)=0,entoncesg∈K,ycomoexistef0 ∈Gcongr(f0)=0(esdecir,f0 ∈
K − {0}), se tiene que g = fg .f0 ∈ < G >. 0
Sea n > 0 y supongamos que todo polinomio de grado menor que n y el polinomio nulo pertenecen a < G >. Sea g ∈ K[X] con gr(g) = n. Por hip ́otesis, existe fn ∈ G con
gr(fn) = n. Si g = Pn ajXj y fn = Pn bjXj, consideramos ge = g − an fn. Observamos
j=0j=0 bnP quege=0ogr(ge)<n. Porhip ́otesisinductiva,ge∈<G>,esdecirge=
cf.f con
cf = 0 salvo para finitos f. En consecuencia,
an X 3 an ́ g=ge+bfn= cf.f+cfn+b fn∈<G>.
n f∈G,f̸=fn
1.2 Sistemas de ecuaciones lineales
n
Hemos visto que un conjunto del tipo

a11x1+···+a1mxm=0  .
S= (x1,...,xm)∈Km: 
an1x1 +···+anmxm =0 
es un subespacio de Km. Surge entonces la cuesti ́on de describir estos conjuntos. Esto puede
hacerse, por ejemplo, encontrando un sistema de generadores del subespacio S.
M ́as en general, estudiaremos el problema de dar una descripci ́on del conjunto de soluciones
de un sistema de ecuaciones de la forma a11x1 +a12x2 +···+a1mxm = b1
.
 an1x1 +an2x2 +···+anmxm = bn
dondeaij ∈Kparatodo1≤i≤ny1≤j≤m,ybi ∈Kparatodo1≤i≤n,alosque llamaremos sistemas de n ecuaciones lineales en m inc ́ognitas.
f∈G
1.2 Sistemas de ecuaciones lineales 13
1.2.1 Sistemas lineales homog ́eneos
Un primer tipo de sistemas de ecuaciones que estudiaremos son los que tienen todas las ecuaciones igualadas a 0.
Definicio ́n 1.16 Un sistema lineal homog ́eneo de n ecuaciones con m inc ́ognitas a coeficientes en un cuerpo K es un sistema del tipo
  a11x1 +a12x2 +···+a1mxm = 0 .
 an1x1 +an2x2 +···+anmxm = 0 dondeaij ∈K paracada1≤i≤n,1≤j≤m.
Notaci ́on. La matriz A ∈ Kn×m definida por Aij = aij se llama la matriz asociada al sistema. Observaci ́on 1.17 El conjunto de las soluciones de un sistema lineal homog ́eneo con m
inco ́gnitas es un subespacio de Km (ver Ejemplo 2 en la p ́agina 10).
Resolver un sistema de este tipo significar ́a dar un sistema de generadores para el subes-
pacio de las soluciones.
El m ́etodo que daremos para la resoluci ́on de sistemas de ecuaciones lineales consiste en transformar el sistema dado, por medio de ciertas operaciones, en otro que tenga el mismo conjunto de soluciones, pero cuya resoluci ́on sea m ́as simple. Aparece entonces la noci ́on de sistemas equivalentes:
Definici ́on 1.18 Dos sistemas lineales homog ́eneos se dicen equivalentes si sus conjuntos de soluciones son iguales.
Ejemplo. Los siguientes sistemas lineales homog ́eneos a coeficientes en R son equivalentes: 1⁄2x+y+z=0 1⁄2 x=0
y+z=0 y+z=0
1.2.2 M ́etodo de triangulaci ́on
Algunos sistemas de ecuaciones lineales son muy f ́aciles de resolver: Ejemplo. Consideremos el siguiente sistema lineal homog ́eneo en R3:
 2 x 1 + 3 x 2 − x 3 = 0

− x2 + x3 = 0 5x3 = 0
Este sistema tiene como u ́nica soluci ́on a (0, 0, 0): De la tercera ecuaci ́on, resulta que x3 = 0. Teniendo en cuenta que x3 = 0, de la segunda ecuaci ́on se deduce que x2 = 0. Finalmente, reemplazando x2 = x3 = 0 en la primera ecuaci ́on, se obtiene que x1 = 0.

14 Espacios vectoriales
An ́alogamente, ser ́a m ́as f ́acil obtener las soluciones de cualquier sistema lineal que se encuentre en esta forma “triangular”, es decir, de la forma
 a11x1 +a12x2 +···+a1nxn +···+a1mxm = 0 a22x2 +···+a2nxn +···+a2mxm = 0
 .
 annxn+···+anmxm = 0
La idea de lo que sigue es ver c ́omo puede obtenerse, dado un sistema lineal arbitrario, un sistema de este tipo equivalente al dado.
La siguiente proposici ́on caracteriza ciertas operaciones que producen sistemas equiva- lentes. En estas operaciones se basa el m ́etodo de eliminaci ́on de Gauss (o m ́etodo de trian- gulaci ́on) que utilizaremos para resolver sistemas lineales.
Proposici ́on 1.19 Dado un sistema lineal homog ́eneo de ecuaciones, los siguientes cambios en las ecuaciones dan lugar a sistemas equivalentes:
1. Intercambiar dos ecuaciones de lugar.
2. Multiplicar una ecuaci ́on por una constante no nula.
3. Reemplazar una ecuaci ́on por ella misma m ́as un mu ́ltiplo de otra.
Demostracio ́n.
1. Si vemos al conjunto de soluciones del sistema como la intersecci ́on de los conjuntos de soluciones de cada una de las ecuaciones que lo integran, intercambiar dos ecuaciones corresponde a intercambiar dos conjuntos en la intersecci ́on. Como la intersecci ́on es conmutativa, el conjunto que resulta es el mismo.
 2. Sea x = (x1,...,xm) ∈ Km una soluci ́on de
a11x1 +a12x2 +···+a1mxm .
ai1x1 +ai2x2 +···+aimxm .
an1x1 +an2x2 +···+anmxm
 (∗)

= 0
= 0
 
= 0
Al multiplicar la i- ́esima ecuaci ́on por λ ∈ K, λ ̸= 0, resulta el sistema
 (∗∗)
 

a11x1 +a12x2 +···+a1mxm
.
λai1x1 +λai2x2 +···+λaimxm .
an1x1 +an2x2 +···+anmxm
= 0 = 0 = 0

1.2 Sistemas de ecuaciones lineales 15
Es claro que x es soluci ́on de todas las ecuaciones que no fueron modificadas. Adem ́as λai1x1 +λai2x2 +···+λaimxm =λ(ai1x1 +ai2x2 +···+aimxm)=λ.0=0.
Luego, x es soluci ́on de (∗∗).
Rec ́ıprocamente, multiplicando la i- ́esima ecuaci ́on de (∗∗) por λ1 se obtiene (∗), de donde, con el mismo razonamiento que antes, se deduce que si x es soluci ́on de (∗∗) tambi ́en lo es de (∗).
3. Se demuestra en forma an ́aloga. ¤
Observaci ́on 1.20 Si A es la matriz asociada a un sistema lineal homog ́eneo H, efectuar las operaciones de la proposici ́on anterior sobre las ecuaciones de H equivale a hacerlo sobre las filas de A.
Como consecuencia de esta observaci ́on, para resolver un sistema lineal trabajaremos con la matriz asociada al sistema, en lugar de hacerlo con las ecuaciones. Al aplicar en las matrices las operaciones dadas en la Proposici ́on 1.19 estaremos obteniendo matrices cuyos sistemas lineales asociados son equivalentes al original.
El siguiente teorema nos asegura que, por medio de las operaciones permitidas siempre puede obtenerse un sistema triangular equivalente al dado. M ́as au ́n, de la demostraci ́on se desprende un algoritmo para realizar esta tarea.
Teorema 1.21 Sea H un sistema lineal homog ́eneo de n ecuaciones con m inc ́ognitas. En- tonces, aplicando los cambios descriptos en la Proposici ́on 1.19, puede obtenerse un sistema lineal homog ́eneo H′ cuya matriz B es triangular superior, es decir, tal que Bij = 0 si i > j.
Demostraci ́on. Procedemos por inducci ́on en n, la cantidad de ecuaciones del sistema. Si n = 1 no hay nada que probar.
Supongamos que vale para n y consideremos un sistema lineal de n + 1 ecuaciones
  

a11x1 +···+a1mxm .
an1x1 +···+anmxm an+11x1 +···+an+1mxm
= 0
= 0
= 0
Si m = 1, es claro que el resultado vale. Supongamos m > 1.
Primer caso: Si ai1 = 0 para cada 1 ≤ i ≤ n+1. Entonces la matriz del sistema es de la
forma
0 an+12 ··· an+1m  ̄0 M donde  ̄0 denota una columna de ceros y c ∈ K1×(m−1), M ∈ Kn×(m−1).
0a···a 12 1m
0c .. .=

16 Espacios vectoriales
Segundo caso: Existe j, 1 ≤ j ≤ n + 1, con a1j ̸= 0. Eventualmente intercambiando las
 ecuaciones 1 y j, podemos suponer que a11 ̸= 0. Multiplicando la primera ecuaci ́on por aplicando operaciones de tipo 3. en las otras resulta
1 y a11
1a12···a1m   a11 a11 1c
a21 a22 ··· a2m Fi−ai1F1   . . .  −→  ̄0 M
an+11 an+12 ··· an+1m con c ∈ K1×(m−1) y M ∈ Kn×(m−1).
Entonces, en cualquier caso, aplicando las operaciones descriptas en la Proposici ́on 1.19 al sistema dado, puede obtenerse un sistema cuya matriz asociada es de la forma
ac
A=
Sea HM el sistema cuya matriz asociada es M. Por hip ́otesis inductiva, aplicando operacio- nes permitidas puede obtenerse un sistema equivalente a HM cuya matriz M′ es triangular superior. Aplicando esas mismas operaciones en la matriz A se obtiene
 ̄0 M
 conM∈Kn×(m−1) y a=1 ́oa=0.
ac
B =  que es triangular superior.
Ejemplo. Resolver el siguiente sistema lineal homog ́eneo en R4:
( 2x2 − x3 + x4 = 0
3x1 +x2 +10x3 +5x4 =0 x1 + 3x3 + x4 = 0
La matriz asociada al sistema de ecuaciones es
0 2 −1 1 A=3 1 10 5.
1031
 ̄0 M′
 con a = 1  ́o a = 0,
El primer paso del m ́etodo de Gauss consiste en colocar en el lugar A11 un elemento no nulo. Para eso permutamos las filas 1 y 3 de la matriz (podr ́ıa usarse tambi ́en la fila 2). Se obtiene
1031 3 1 10 5.
0 2 −1 1
¤

1.2 Sistemas de ecuaciones lineales 17
A continuaci ́on debemos realizar operaciones de fila de manera de conseguir que los restantes elementos de la primera columna de la matriz sean ceros. Si Fi denota la i- ́esima fila de la matriz, haciendo F2 − 3F1 resulta
1031 0112.
0 2 −1 1
Pasamos ahora a la segunda columna de la matriz. El elemento ubicado en la fila 2 columna 2 de la matriz es un 1, con lo que s ́olo resta conseguir un 0 en la fila 3 columna 2. Para eso
 efectuamos F3 − 2F2:
1031 0112.
0 0 −3 −3
Esta matriz se encuentra en forma triangular. El sistema asociado
( x1 + 3x3 + x4 = 0 x2 + x3 + 2x4 = 0 −3x3 − 3x4 = 0
es equivalente al original.
De la tercera ecuaci ́on deducimos que si X = (x1, x2, x3, x4) es soluci ́on del sistema, entonces x3 = −x4. Reemplazando en la segunda ecuaci ́on y despejando x2 se obtiene x2 = −x4. Finalmente, de la primera ecuaci ́on se deduce que x1 = 2x4. Adem ́as es claro que cualquier X que cumple estas condiciones es soluci ́on de la ecuaci ́on.
En consecuencia, las soluciones del sistema son todos los vectores en R4 de la forma X = (2x4, −x4, −x4, x4) = x4(2, −1, −1, 1), es decir, el conjunto de las soluciones del sistema es el subespacio
S = < (2,−1,−1,1) >.
1.2.3 Cantidad de soluciones de un sistema homog ́eneo
Una consecuencia inmediata del Teorema 1.21 es la siguiente:
Observaci ́on 1.22 Sea H un sistema lineal homog ́eneo de n ecuaciones con m inc ́ognitas. Supongamos que n > m. Entonces, por el teorema anterior, el sistema es equivalente a uno cuya matriz es triangular superior. Luego, las u ́ltimas filas de su matriz asociada son nulas y en consecuencia vemos que existe un sistema H′ de n ecuaciones con n inc ́ognitas cuyo conjunto de soluciones coincide con el de H (basta considerar las n primeras ecuaciones del sistema obtenido).
Si H es un sistema lineal homog ́eneo con m inc ́ognitas, es claro que 0 ∈ Km es una soluci ́on de H. E ́sta se llama la soluci ́on trivial del sistema. En muchos casos nos interesar ́a saber si el sistema tiene alguna soluci ́on distinta de 0 (a las que llamaremos soluciones no triviales). El siguiente resultado nos dice que en el caso de un sistema con menos ecuaciones que inc ́ognitas esto siempre sucede.

18 Espacios vectoriales
Teorema 1.23 Sea H un sistema lineal homog ́eneo de n ecuaciones con m inc ́ognitas. Su- pongamos que n < m. Entonces existe x ∈ Km, x ̸= 0, que es soluci ́on del sistema H.
Demostracio ́n. Por inducci ́on en la cantidad n de ecuaciones de H.
Si n = 1,m ≥ 2: Entonces H : a11x1 +a12x2···+a1mxm = 0. Si a11 = 0, entonces
(1,0,...,0) es soluci ́on del sistema y si a11 ̸= 0, entonces (−a12 ,1,0,...,0) es soluci ́on. a11
Supongamos que el resultado vale para sistemas con n ecuaciones y sea H un sistema de n + 1 ecuaciones con m inc ́ognitas, n + 1 < m.
Triangulando la matriz del sistema, resulta que es equivalente a una de la forma
μaa···a¶ 11 12 1m ,
0B donde B ∈ Kn×(m−1), y m − 1 > n.
Por lo tanto, el sistema cuya matriz asociada es B est ́a en las condiciones de la hip ́otesis inductiva. Luego, existe (x1, . . . , xm−1) ̸= 0 que es soluci ́on del sistema asociado a B.
• Si a11 = 0, entonces (1, 0, . . . , 0) es soluci ́on del sistema original.
 • Si a11 ̸= 0, entonces − a11 . sistema.
i=2
a1ixi−1 ,x1,...,xm−1
es una soluci ́on no nula del
¤
31¡Pm ¢  ́
El siguiente teorema se refiere a la existencia de soluciones no triviales para sistemas ho- mog ́eneos con igual cantidad de ecuaciones que inc ́ognitas. Teniendo en cuenta la observaci ́on hecha la comienzo de esta secci ́on, esto resuelve el problema en el caso general.
Teorema 1.24 Sea H un sistema lineal homog ́eneo de n ecuaciones y n inc ́ognitas. Sea H′ un sistema equivalente a H cuya matriz B es triangular superior. Entonces H tiene soluci ́on u ́nica si y s ́olo si Bii ̸=0 ∀1≤i≤n.
Demostracio ́n.
B···B 11 1n
(⇐) SupongamosqueB= 0 ... . conBii ̸=0∀1≤i≤n. ··· 0 Bnn
Entonces, la u ́ltima ecuaci ́on del sistema H′ es Bnnxn = 0 y, como Bnn ̸= 0, resulta que xn = 0. Reemplazando en la ecuaci ́on anterior xn por 0, queda Bn−1 n−1xn−1 = 0, de donde xn−1 = 0.
Siguiendo de este modo, para cada k = n − 2, . . . , 1 de la k- ́esima ecuaci ́on se obtiene xk = 0.

1.2 Sistemas de ecuaciones lineales
(⇒) Supongamos que B11 ̸= 0,...,Bii ̸= 0 y Bi+1i+1 = 0, o sea B···B
 0 ...
 . ... B B
19
 sea xi+1 = 1,...,xn = 0.
De la i- ́esima ecuaci ́on se despeja xi = −Bi i+1 .
11
1n
. 
 ii ii+1 000   . . . M 
0···00
Es claro que (1,0,...,0) es soluci ́on del sistema cuya matriz asociada es ¡ 0
M ¢, o Se sigue as ́ı para calcular los valores de todas las variables. Se obtiene una soluci ́on de
··· B  in 
 Bii
H′ de la forma (x1,...,xi,1,0,...,0), que es una soluci ́on no nula del sistema. ¤
Ejemplo. Hallar todos los valores de k ∈ R para los cuales el sistema homog ́eneo cuya matriz 12k−1
asociada es  2 −k + 1 1  tiene soluci ́on u ́nica. k+1 −4 1